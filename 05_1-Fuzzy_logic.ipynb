{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import ks_2samp\n",
    "from IPython.display import Image\n",
    "\n",
    "import shap\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "import xgboost as xgb\n",
    "from plot_learning import *\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, RandomizedSearchCV\n",
    "from sklearn.metrics  import average_precision_score, make_scorer, roc_curve,f1_score, precision_score, recall_score, fbeta_score, auc, roc_auc_score, accuracy_score, confusion_matrix, classification_report,precision_recall_curve\n",
    "# from skopt import BayesSearchCV\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "X_train = pd.read_csv(\"X_train.csv\", sep = \";\")\n",
    "X_test = pd.read_csv(\"X_test.csv\", sep = \";\")\n",
    "\n",
    "y_train = pd.read_csv(\"y_train.csv\", sep = \";\")\n",
    "y_test = pd.read_csv(\"y_test.csv\", sep = \";\")\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removendo variáveis \n",
    "X_train = X_train.drop([\n",
    "'H1RFV', 'H1LFV', 'H1RRO'\n",
    "], axis=1)\n",
    "\n",
    "X_test = X_test.drop([\n",
    "'H1RFV', 'H1LFV', 'H1RRO'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.GR.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.GR.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    \n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(y_train_enc).keys())\n",
    "print(Counter(y_train_enc).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(y_test_enc).keys())\n",
    "print(Counter(y_test_enc).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_std = \"./models/std.pickle\"\n",
    "# file_smote = \"./models/smote.pickle\"\n",
    "\n",
    "std = joblib.load(file_std)\n",
    "# smote= joblib.load(file_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_std_smote = \"./models/std_smote.pickle\"\n",
    "file_smote = \"./models/smote.pickle\"\n",
    "\n",
    "std_smote = joblib.load(file_std_smote)\n",
    "smote= joblib.load(file_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = std.transform(X_train)\n",
    "X_test_std = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_smote = std_smote.transform(X_train)\n",
    "X_test_std_smote = std_smote.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = smote.fit_resample(X_train_std_smote, y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_print(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    # print(\"Confusion Matrix: \\n\", confusion_matrix(y_test_test, y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    index =[\"A\", \"B\", \"C\"]\n",
    "    columns =[\"A\", \"B\", \"C\"]\n",
    "    cm_df = pd.DataFrame(cm,columns,index)                      \n",
    "    plt.figure(figsize=(8,6))  \n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_1 = './models/RF_best_bayes.sav'\n",
    "filename_2 = './models/SVM_best_bayes.sav'\n",
    "filename_3 = './models/LR_best_bayes.sav'\n",
    "filename_4 = './models/KNN_best_bayes.sav'\n",
    "filename_5 = './models/GBM_best_bayes.sav'\n",
    "\n",
    "\n",
    "RF_best = joblib.load(filename_1)\n",
    "SVM_best = joblib.load(filename_2)\n",
    "LR_best = joblib.load(filename_3)\n",
    "KNN_best = joblib.load(filename_4)\n",
    "GBM_best = joblib.load(filename_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF = pd.Series(RF_best.predict(X_test_std), name=\"RF\")\n",
    "model_LR = pd.Series(LR_best.predict(X_test_std), name= \"LR\")\n",
    "model_SVM = pd.Series(SVM_best.predict(X_test_std), name=\"SVM\")\n",
    "model_GBM = pd.Series(GBM_best.predict(X_test_std), name=\"GBM\")\n",
    "model_KNN = pd.Series(KNN_best.predict(X_test_std), name=\"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "tau, p_value = stats.kendalltau(model_RF, model_GBM)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_print_v2(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test_enc, y_pred)\n",
    "    index =[\"A\", \"B\", \"C\"]\n",
    "    columns =[\"A\", \"B\", \"C\"]\n",
    "    cm_df = pd.DataFrame(cm,columns,index)                      \n",
    "    plt.figure(figsize=(8,6))  \n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test_enc, y_pred))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_print_v2(RF_best, X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os modelos\n",
    "models = [\n",
    "    # ('rf', RF_best),\n",
    "    # ('svm', SVM_best),\n",
    "    ('lr', LR_best),\n",
    "    # ('knn', KNN_best),\n",
    "    ('gbm', GBM_best)\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ensemble\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "\n",
    "ensemble_model.fit(X_train_std, y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter previsões probabilísticas do ensemble\n",
    "ensemble_proba_train = ensemble_model.predict(X_train_std)\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc, ensemble_proba_train))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter previsões probabilísticas do ensemble\n",
    "ensemble_proba = ensemble_model.predict_proba(X_test_std)\n",
    "fit_and_print_v2(ensemble_model, X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "# data_train[\"prob_rf\"] = RF_best.predict_proba(X_train_std)[:,0]\n",
    "data_train[\"prob_lr\"] = LR_best.predict_proba(X_train_std)[:,0]\n",
    "data_train[\"prob_gbm\"] = GBM_best.predict_proba(X_train_std)[:,0]\n",
    "\n",
    "print(\"A\", data_train[data_train['y']=='A'][['prob_lr', 'prob_gbm']].mean(axis=1).describe())\n",
    "print(\"B\", data_train[data_train['y']=='B'][['prob_lr', 'prob_gbm']].mean(axis=1).describe())\n",
    "print(\"C\", data_train[data_train['y']=='C'][['prob_lr', 'prob_gbm']].mean(axis=1).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = [0.99, 0.004]\n",
    "medium = [0.28, 0.08]\n",
    "low = [0.21, 0.04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "data_train[\"prob_rf\"] = RF_best.predict_proba(X_train_std)[:,1]\n",
    "data_train[\"prob_svm\"] = SVM_best.predict_proba(X_train_std)[:,1]\n",
    "data_train[\"prob_gbm\"] = GBM_best.predict_proba(X_train_std)[:,1]\n",
    "\n",
    "print(\"A\", data_train[data_train['y']=='A'][['prob_rf', 'prob_svm', 'prob_gbm']].mean(axis=1).describe())\n",
    "print(\"B\", data_train[data_train['y']=='B'][['prob_rf', 'prob_svm', 'prob_gbm']].mean(axis=1).describe())\n",
    "print(\"C\", data_train[data_train['y']=='C'][['prob_rf', 'prob_svm', 'prob_gbm']].mean(axis=1).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = [0.89, 0.03]\n",
    "medium = [0.35, 0.10]\n",
    "low = [0.30, 0.13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "data_train[\"prob_rf\"] = RF_best.predict_proba(X_train_std)[:,2]\n",
    "data_train[\"prob_svm\"] = SVM_best.predict_proba(X_train_std)[:,2]\n",
    "data_train[\"prob_gbm\"] = GBM_best.predict_proba(X_train_std)[:,2]\n",
    "\n",
    "\n",
    "print(\"A\", data_train[data_train['y']=='A'][['prob_rf', 'prob_svm', 'prob_gbm']].mean(axis=1).describe())\n",
    "print(\"B\", data_train[data_train['y']=='B'][['prob_rf', 'prob_svm', 'prob_gbm']].mean(axis=1).describe())\n",
    "print(\"C\", data_train[data_train['y']=='C'][['prob_rf', 'prob_svm', 'prob_gbm']].mean(axis=1).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = [0.82, 0.07]\n",
    "medium = [0.12, 0.05]\n",
    "low = [0.07, 0.01]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## A ############\n",
    "high = [0.99, 0.004]\n",
    "medium = [0.28, 0.08]\n",
    "low = [0.21, 0.04]\n",
    "########## B ############\n",
    "high = [0.89, 0.03]\n",
    "medium = [0.35, 0.10]\n",
    "low = [0.30, 0.13]\n",
    "########## C ############\n",
    "high = [0.82, 0.07]\n",
    "medium = [0.12, 0.05]\n",
    "low = [0.07, 0.01]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_by_rule(data, class_column, id, prob_columns):\n",
    "\n",
    "    results = {}\n",
    "    for class_label in data[class_column].unique():\n",
    "        class_data = data[data[class_column] == class_label]\n",
    "        mean_probs = class_data[prob_columns].mean(axis=1)\n",
    "        mean_value = mean_probs.mean()\n",
    "        std_value = mean_probs.std()\n",
    "\n",
    "        results[class_label] = {\"class\": id, \"mean\": mean_value, \"std\": std_value}\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def prob_class(data_train, train_set, id_class):\n",
    "\n",
    "    prob_columns = []\n",
    "    for i, model_probs in enumerate(train_set):\n",
    "        column_name = f\"prob_model_{i+1}\"\n",
    "        data_train[column_name] = model_probs[:, id_class]\n",
    "        prob_columns.append(column_name)\n",
    "        return prob_columns\n",
    "\n",
    "\n",
    "def return_means_std(data_train, train_set):\n",
    "\n",
    "    classifications = []\n",
    "\n",
    "    for id_class in range(0, 3):\n",
    "\n",
    "        prob_columns = prob_class(data_train, train_set, id_class)\n",
    "        classification = classify_by_rule(data_train, class_column=\"y\", id = id_class, prob_columns=prob_columns)\n",
    "        classifications.append(classification)\n",
    "\n",
    "    class_1_high_mean = classifications[0]['A']['mean']\n",
    "    class_1_medium_mean = classifications[0]['B']['mean']\n",
    "    class_1_low_mean = classifications[0]['C']['mean']\n",
    "\n",
    "    class_1_high_std = classifications[0]['A']['std']\n",
    "    class_1_medium_std = classifications[0]['B']['std']\n",
    "    class_1_low_std = classifications[0]['C']['std']\n",
    "\n",
    "\n",
    "    class_2_high_mean = classifications[1]['B']['mean']\n",
    "    class_2_medium_mean = classifications[1]['C']['mean']\n",
    "    class_2_low_mean = classifications[1]['A']['mean']\n",
    "\n",
    "    class_2_high_std = classifications[1]['B']['std']\n",
    "    class_2_medium_std = classifications[1]['C']['std']\n",
    "    class_2_low_std = classifications[1]['A']['std']\n",
    "\n",
    "\n",
    "    class_3_high_mean = classifications[2]['C']['mean']\n",
    "    class_3_medium_mean = classifications[2]['B']['mean']\n",
    "    class_3_low_mean = classifications[2]['A']['mean']\n",
    "\n",
    "    class_3_high_std = classifications[2]['C']['std']\n",
    "    class_3_medium_std = classifications[2]['B']['std']\n",
    "    class_3_low_std = classifications[2]['A']['std']\n",
    "\n",
    "    mean_values  = [[class_1_high_mean, class_1_medium_mean, class_1_low_mean], [class_2_high_mean, class_2_medium_mean, class_2_low_mean], [class_3_high_mean, class_3_medium_mean, class_3_low_mean]]\n",
    "\n",
    "    std_values  = [[class_1_high_std, class_1_medium_std, class_1_low_std], [class_2_high_std, class_2_medium_std, class_2_low_std], [class_3_high_std, class_3_medium_std, class_3_low_std]]\n",
    "    \n",
    "    return mean_values, std_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "\n",
    "class FuzzyClassifier:\n",
    "    def __init__(self, mean_values, std_values):\n",
    "        self.prob_classe1 = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'Probability for category A')\n",
    "        self.prob_classe2 = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'Probability for category B')\n",
    "        self.prob_classe3 = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'Probability for category C')\n",
    "        self.classe_final = ctrl.Consequent(np.arange(1, 4, 1), 'Final classification')\n",
    "\n",
    "        m_c1_high = mean_values[0][0]\n",
    "        m_c1_medium = mean_values[0][1]\n",
    "        m_c1_low = mean_values[0][2]\n",
    "\n",
    "        m_c2_high = mean_values[1][0]\n",
    "        m_c2_medium = mean_values[1][1]\n",
    "        m_c2_low = mean_values[1][2]\n",
    "\n",
    "        m_c3_high = mean_values[2][0]\n",
    "        m_c3_medium = mean_values[2][1]\n",
    "        m_c3_low = mean_values[2][2]\n",
    "\n",
    "        s_c1_high = std_values[0][0]\n",
    "        s_c1_medium = std_values[0][1]\n",
    "        s_c1_low = std_values[0][2]\n",
    "\n",
    "        s_c2_high = std_values[1][0]\n",
    "        s_c2_medium = std_values[1][1]\n",
    "        s_c2_low = std_values[1][2]\n",
    "\n",
    "        s_c3_high = std_values[2][0]\n",
    "        s_c3_medium = std_values[2][1]\n",
    "        s_c3_low = std_values[2][2]\n",
    "\n",
    "\n",
    "        self._define_membership_functions(m_c1_high, m_c1_medium, m_c1_low, m_c2_high, m_c2_medium, m_c2_low, m_c3_high, \n",
    "                                          m_c3_medium, m_c3_low, s_c1_high, s_c1_medium, s_c1_low, s_c2_high, s_c2_medium,\n",
    "                                          s_c2_low, s_c3_high, s_c3_medium, s_c3_low)\n",
    "\n",
    "        self.classe_final['Category A'] = fuzz.trimf(self.classe_final.universe, [0.5, 1, 1.5])\n",
    "        self.classe_final['Category B'] = fuzz.trimf(self.classe_final.universe, [1.5, 2, 2.5])\n",
    "        self.classe_final['Category C'] = fuzz.trimf(self.classe_final.universe, [2.5, 3, 3.5])\n",
    "\n",
    "        self.classe_final.defuzzify_method = 'centroid'#'mom'\n",
    "\n",
    "        self.rules = self._define_rules()\n",
    "\n",
    "        self.classification_ctrl = ctrl.ControlSystem(self.rules)\n",
    "        self.classification = ctrl.ControlSystemSimulation(self.classification_ctrl)\n",
    "\n",
    "    def _define_membership_functions(self, m_c1_high, m_c1_medium, m_c1_low, m_c2_high, m_c2_medium, m_c2_low, m_c3_high, \n",
    "                                          m_c3_medium, m_c3_low, s_c1_high, s_c1_medium, s_c1_low, s_c2_high, s_c2_medium,\n",
    "                                          s_c2_low, s_c3_high, s_c3_medium, s_c3_low):\n",
    "        \n",
    "\n",
    "        self.prob_classe1['low'] = fuzz.gaussmf(self.prob_classe1.universe, m_c1_low, s_c1_low)\n",
    "        self.prob_classe1['medium'] = fuzz.gaussmf(self.prob_classe1.universe, m_c1_medium, s_c1_medium)\n",
    "        self.prob_classe1['high'] = fuzz.gaussmf(self.prob_classe1.universe, m_c1_high, s_c1_high)\n",
    "\n",
    "        self.prob_classe2['low'] = fuzz.gaussmf(self.prob_classe2.universe, m_c2_low, s_c2_low)\n",
    "        self.prob_classe2['medium'] = fuzz.gaussmf(self.prob_classe2.universe, m_c2_medium, s_c2_medium)\n",
    "        self.prob_classe2['high'] = fuzz.gaussmf(self.prob_classe2.universe, m_c2_high, s_c2_high)\n",
    "\n",
    "        self.prob_classe3['low'] = fuzz.gaussmf(self.prob_classe3.universe, m_c3_low, s_c3_low)\n",
    "        self.prob_classe3['medium'] = fuzz.gaussmf(self.prob_classe3.universe, m_c3_medium, s_c3_medium)\n",
    "        self.prob_classe3['high'] = fuzz.gaussmf(self.prob_classe3.universe, m_c3_high, s_c3_high)\n",
    "\n",
    "    def _define_rules(self):\n",
    "        rules = [\n",
    "                ctrl.Rule(self.prob_classe1['low'] & self.prob_classe2['medium'] & self.prob_classe3['high'], self.classe_final['Category C']),\n",
    "                ctrl.Rule(self.prob_classe1['low'] & self.prob_classe2['low'] & self.prob_classe3['medium'], self.classe_final['Category C']),\n",
    "                ctrl.Rule(self.prob_classe1['low'] & self.prob_classe2['medium'] & self.prob_classe3['medium'], self.classe_final['Category B']),\n",
    "                ctrl.Rule(self.prob_classe1['low'] & self.prob_classe2['medium'] & self.prob_classe3['low'], self.classe_final['Category B']),\n",
    "                ctrl.Rule(self.prob_classe1['low'] & self.prob_classe2['high'] & self.prob_classe3['low'], self.classe_final['Category B']),\n",
    "                ctrl.Rule(self.prob_classe1['low'] & self.prob_classe2['high'] & self.prob_classe3['medium'], self.classe_final['Category B']),\n",
    "                ctrl.Rule(self.prob_classe1['low'] & self.prob_classe2['high'] & self.prob_classe3['high'], self.classe_final['Category C']),\n",
    "\n",
    "                ctrl.Rule(self.prob_classe1['medium'] & self.prob_classe2['low'] & self.prob_classe3['low'], self.classe_final['Category A']),\n",
    "                ctrl.Rule(self.prob_classe1['medium'] & self.prob_classe2['low'] & self.prob_classe3['medium'], self.classe_final['Category C']),\n",
    "                ctrl.Rule(self.prob_classe1['medium'] & self.prob_classe2['low'] & self.prob_classe3['high'], self.classe_final['Category C']),\n",
    "                ctrl.Rule(self.prob_classe1['medium'] & self.prob_classe2['medium'] & self.prob_classe3['low'], self.classe_final['Category A']),\n",
    "                ctrl.Rule(self.prob_classe1['medium'] & self.prob_classe2['medium'] & self.prob_classe3['medium'], self.classe_final['Category B']),\n",
    "                ctrl.Rule(self.prob_classe1['medium'] & self.prob_classe2['medium'] & self.prob_classe3['high'], self.classe_final['Category C']),\n",
    "                ctrl.Rule(self.prob_classe1['medium'] & self.prob_classe2['high'] & self.prob_classe3['low'], self.classe_final['Category B']),\n",
    "                ctrl.Rule(self.prob_classe1['medium'] & self.prob_classe2['high'] & self.prob_classe3['medium'], self.classe_final['Category B']),\n",
    "                ctrl.Rule(self.prob_classe1['medium'] & self.prob_classe2['high'] & self.prob_classe3['high'], self.classe_final['Category C']),\n",
    "\n",
    "                ctrl.Rule(self.prob_classe1['high'] & self.prob_classe2['low'] & self.prob_classe3['low'], self.classe_final['Category A']),\n",
    "                ctrl.Rule(self.prob_classe1['high'] & self.prob_classe2['low'] & self.prob_classe3['medium'], self.classe_final['Category A']),\n",
    "                ctrl.Rule(self.prob_classe1['high'] & self.prob_classe2['low'] & self.prob_classe3['high'], self.classe_final['Category C']),\n",
    "                ctrl.Rule(self.prob_classe1['high'] & self.prob_classe2['medium'] & self.prob_classe3['low'], self.classe_final['Category A']),\n",
    "                ctrl.Rule(self.prob_classe1['high'] & self.prob_classe2['medium'] & self.prob_classe3['medium'], self.classe_final['Category A']),\n",
    "                ctrl.Rule(self.prob_classe1['high'] & self.prob_classe2['medium'] & self.prob_classe3['high'], self.classe_final['Category C']),\n",
    "                ctrl.Rule(self.prob_classe1['high'] & self.prob_classe2['high'] & self.prob_classe3['low'], self.classe_final['Category A']),\n",
    "                ctrl.Rule(self.prob_classe1['high'] & self.prob_classe2['high'] & self.prob_classe3['medium'], self.classe_final['Category A']),\n",
    "                ctrl.Rule(self.prob_classe1['high'] & self.prob_classe2['high'] & self.prob_classe3['high'], self.classe_final['Category C'])\n",
    "        ]\n",
    "        return rules\n",
    "\n",
    "    def classify(self, dataset):\n",
    "        results = []\n",
    "        for i in range(len(dataset[0])):\n",
    "            models_probabilities = [model[i] for model in dataset]\n",
    "\n",
    "            prob_C1 = np.max([prob[0] for prob in models_probabilities])\n",
    "\n",
    "            prob_C2 = np.max([prob[1] for prob in models_probabilities])\n",
    "\n",
    "            prob_C3 = np.max([prob[2] for prob in models_probabilities])\n",
    "\n",
    "\n",
    "            self.classification.input['Probability for category A'] = prob_C1\n",
    "            self.classification.input['Probability for category B'] = prob_C2\n",
    "            self.classification.input['Probability for category C'] = prob_C3\n",
    "\n",
    "            self.classification.compute()\n",
    "            results.append(int(round(self.classification.output['Final classification'])))\n",
    "\n",
    "        return [0 if r == 1 else 1 if r == 2 else 2 for r in results]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF + GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [\n",
    "    ('rf', RF_best),\n",
    "    ('gbm', GBM_best),\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_rf_gbm = ensemble_model.predict_proba(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [ensemble_proba_train_rf_gbm]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_rf_gbm = ensemble_model.predict_proba(X_test_std)\n",
    "\n",
    "test_set = [ensemble_proba_test_rf_gbm]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF + GBM + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [\n",
    "    ('rf', RF_best),\n",
    "    ('gbm', GBM_best),\n",
    "    ('lr', LR_best),\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_rf_gbm_lr = ensemble_model.predict_proba(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [ensemble_proba_train_rf_gbm_lr]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)\n",
    "\n",
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_rf_gbm_lr = ensemble_model.predict_proba(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [ensemble_proba_test_rf_gbm_lr]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('rf', RF_best),\n",
    "    ('lr', LR_best),\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_rf_lr = ensemble_model.predict_proba(X_train_std)\n",
    "ensemble_train_rf_lr = ensemble_model.predict(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [ensemble_proba_train_rf_lr]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)\n",
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_rf_lr = ensemble_model.predict_proba(X_test_std)\n",
    "\n",
    "ensemble_test_rf_lr = ensemble_model.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [ensemble_proba_test_rf_lr]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBM + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('rf', RF_best),\n",
    "    ('gbm', GBM_best),\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_lr_gbm = ensemble_model.predict_proba(X_train_std)\n",
    "\n",
    "ensemble_train_lr_gbm = ensemble_model.predict(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [ensemble_proba_train_lr_gbm]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)\n",
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_lr_gbm = ensemble_model.predict_proba(X_test_std)\n",
    "\n",
    "ensemble_test_lr_gbm = ensemble_model.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [ensemble_proba_test_lr_gbm]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF + GBM + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('rf', RF_best),\n",
    "    ('gbm', GBM_best),\n",
    "    ('svm', SVM_best)\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_lr_gbm_svm = ensemble_model.predict_proba(X_train_std)\n",
    "\n",
    "train_set = [ensemble_proba_train_lr_gbm_svm]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)\n",
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_lr_gbm_svm = ensemble_model.predict_proba(X_test_std)\n",
    "\n",
    "test_set = [ensemble_proba_test_lr_gbm_svm]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF + GBM + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('rf', RF_best),\n",
    "    ('gbm', GBM_best),\n",
    "    ('knn', KNN_best)\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_lr_gbm_knn = ensemble_model.predict_proba(X_train_std)\n",
    "\n",
    "train_set = [ensemble_proba_train_lr_gbm_knn]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)\n",
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_lr_gbm_knn = ensemble_model.predict_proba(X_test_std)\n",
    "\n",
    "test_set = [ensemble_proba_test_lr_gbm_knn]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('rf', RF_best),\n",
    "    ('knn', KNN_best)\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_rf_knn = ensemble_model.predict_proba(X_train_std)\n",
    "\n",
    "train_set = [ensemble_proba_train_rf_knn]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)\n",
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_rf_knn = ensemble_model.predict_proba(X_test_std)\n",
    "\n",
    "test_set = [ensemble_proba_test_rf_knn]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('gbm', GBM_best),\n",
    "    ('svm', SVM_best)\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_gbm_svm = ensemble_model.predict_proba(X_train_std)\n",
    "\n",
    "train_set = [ensemble_proba_train_gbm_svm]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)\n",
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_gbm_svm = ensemble_model.predict_proba(X_test_std)\n",
    "\n",
    "test_set = [ensemble_proba_test_gbm_svm]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('gbm', GBM_best),\n",
    "    ('knn', KNN_best)\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_gbm_knn = ensemble_model.predict_proba(X_train_std)\n",
    "\n",
    "train_set = [ensemble_proba_train_gbm_knn]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)\n",
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_gbm_knn = ensemble_model.predict_proba(X_test_std)\n",
    "\n",
    "test_set = [ensemble_proba_test_gbm_knn]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('rf', RF_best),\n",
    "    ('svm', SVM_best)\n",
    "]\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble_model.fit(X_train_std, y_train_enc)\n",
    "\n",
    "ensemble_proba_train_rf_svm = ensemble_model.predict_proba(X_train_std)\n",
    "\n",
    "train_set = [ensemble_proba_train_rf_svm]\n",
    "\n",
    "data_train = pd.DataFrame()\n",
    "data_train['y'] = y_train.GR\n",
    "\n",
    "means_, std_ = return_means_std(data_train, train_set)\n",
    "\n",
    "classifier = FuzzyClassifier(means_, std_)\n",
    "resultados_train = classifier.classify(train_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_train}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_train_enc,  resultados_train))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_train_enc, resultados_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_test_rf_svm = ensemble_model.predict_proba(X_test_std)\n",
    "\n",
    "test_set = [ensemble_proba_test_rf_svm]\n",
    "\n",
    "resultados_test= classifier.classify(test_set)\n",
    "\n",
    "print(f'Resultados da classificação: {resultados_test}')\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_enc,  resultados_test))\n",
    "print(\"confusion matrixt: \\n\",confusion_matrix(y_test_enc, resultados_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation of rules with graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create the graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes for the fuzzy variables\n",
    "G.add_node('Prob. A', type='input A')\n",
    "G.add_node('Prob. B', type='input B')\n",
    "G.add_node('Prob. C', type='input C')\n",
    "G.add_node('Final classification', type='output')\n",
    "\n",
    "# Add edges representing the rules\n",
    "for idx, rule in enumerate(classifier.rules):\n",
    "    rule_name = f'Rule {idx + 1}'\n",
    "    G.add_node(rule_name, type='rule')\n",
    "\n",
    "    # Connect the antecedent variables to the rule\n",
    "    G.add_edge('Prob. A', rule_name)\n",
    "    G.add_edge('Prob. B', rule_name)\n",
    "    G.add_edge('Prob. C', rule_name)\n",
    "\n",
    "    # Connect the rule to the consequent variable\n",
    "    G.add_edge(rule_name, 'Final classification')\n",
    "\n",
    "# Generate starting positions for nodes\n",
    "pos = nx.spring_layout(G, dim=3, seed=42, k=0.5)  \n",
    "\n",
    "# Manually adjust positions for \"Prob. A\", \"Prob. B\" and \"Prob. C\"\n",
    "pos['Prob. A'] = np.array([-1.5, 0, 0.5])  \n",
    "pos['Prob. B'] = np.array([0, 1.5, -0.5])  \n",
    "pos['Prob. C'] = np.array([1.5, 0, 0.5]) \n",
    "\n",
    "x_nodes = [pos[node][0] for node in G.nodes]\n",
    "y_nodes = [pos[node][1] for node in G.nodes]\n",
    "z_nodes = [pos[node][2] for node in G.nodes]\n",
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "edge_z = []\n",
    "\n",
    "for edge in G.edges:\n",
    "    x0, y0, z0 = pos[edge[0]]\n",
    "    x1, y1, z1 = pos[edge[1]]\n",
    "    edge_x.extend([x0, x1, None])\n",
    "    edge_y.extend([y0, y1, None])\n",
    "    edge_z.extend([z0, z1, None])\n",
    "\n",
    "node_colors = []\n",
    "for node in G.nodes:\n",
    "    if G.nodes[node]['type'] == 'input A':\n",
    "        node_colors.append('green')  # Prob. A\n",
    "    elif G.nodes[node]['type'] == 'input B':\n",
    "        node_colors.append('orange')  # Prob. B\n",
    "    elif G.nodes[node]['type'] == 'input C':\n",
    "        node_colors.append('red')  # Prob. C\n",
    "    elif G.nodes[node]['type'] == 'output':\n",
    "        node_colors.append('blue')  # Output\n",
    "    else:\n",
    "        node_colors.append('lightblue')  # Rules\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=edge_x, y=edge_y, z=edge_z,\n",
    "    mode='lines',\n",
    "    line=dict(color='gray', width=2),\n",
    "    hoverinfo='none'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x_nodes, y=y_nodes, z=z_nodes,\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=10, color=node_colors, line=dict(width=0.1, color='black')),\n",
    "    text=list(G.nodes),\n",
    "    textposition='top center',\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Grafo de Regras Fuzzy (3D)',\n",
    "    scene=dict(\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "        zaxis=dict(visible=False)\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=10, b=0),\n",
    "    paper_bgcolor='white'  # Fundo geral branco\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_classe1 = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'Probability for category A')\n",
    "prob_classe2 = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'Probability for category B')\n",
    "prob_classe3 = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'Probability for category C')\n",
    "classe_final = ctrl.Consequent(np.arange(1, 4, 1), 'Final classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_classe1['low'] = fuzz.gaussmf(prob_classe1.universe, 0.09, 0.03)\n",
    "prob_classe1['medium'] = fuzz.gaussmf(prob_classe1.universe, 0.14, 0.06)\n",
    "prob_classe1['high'] = fuzz.gaussmf(prob_classe1.universe, 0.81, 0.09)\n",
    "\n",
    "prob_classe1.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_classe2['low'] = fuzz.gaussmf(prob_classe2.universe, 0.15, 0.08)\n",
    "prob_classe2['medium'] = fuzz.gaussmf(prob_classe2.universe, 0.25, 0.07)\n",
    "prob_classe2['high'] = fuzz.gaussmf(prob_classe2.universe, 0.76, 0.06)\n",
    "prob_classe2.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_classe3['low'] =  fuzz.gaussmf(prob_classe3.universe, 0.03, 0.01)\n",
    "prob_classe3['medium'] = fuzz.gaussmf(prob_classe3.universe, 0.09, 0.03)\n",
    "prob_classe3['high'] = fuzz.gaussmf(prob_classe3.universe, 0.65, 0.09)\n",
    "prob_classe3.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_classe3 = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'prob_classe3')\n",
    "classe_final = ctrl.Consequent(np.arange(1, 4, 1), 'Final classification')\n",
    "\n",
    "classe_final['category A'] = fuzz.trimf(classe_final.universe, [0.5, 1, 1.8]) \n",
    "classe_final['category B'] = fuzz.trimf(classe_final.universe, [1.4, 2, 2.5]) \n",
    "classe_final['category C'] = fuzz.trimf(classe_final.universe, [2.2, 3, 3.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_final.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
